{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n  DeprecationWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "(10, 10000)\n",
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n--------      --------      --------      --------      --------      \ndirector      show          book          family        funny         \nwork          series        original      young         comedy        \nperformance   war           10            father        cast          \nactors        episode       now           us            role          \ncast          tv            again         woman         humor         \nscreen        years         world         own           fun           \nperformances  american      saw           world         jokes         \nrole          episodes      read          real          actors        \nboth          world         didn          mother        performance   \nquite         shows         am            between       always        \n\n\ntopic 5       topic 6       topic 7       topic 8       topic 9       \n--------      --------      --------      --------      --------      \nhorror        music         original      thing         action        \ngore          john          team          worst         police        \neffects       old           series        didn          murder        \nblood         young         jack          nothing       killer        \npretty        girl          action        minutes       crime         \nbudget        song          new           guy           plays         \nhouse         gets          down          actually      lee           \nzombie        dance         tarzan        want          gets          \ndead          songs         freddy        going         role          \nlow           rock          indian        re            cop           \n\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "'''\n",
    "隐含狄利克雷分布\n",
    "从直观上来看，LDA 模型试图找出频繁共同出现的单词群组（即主题）。LDA 还要求，每\n",
    "个文档可以被理解为主题子集的“混合”。重要的是要理解，机器学习模型所谓的“主\n",
    "题”可能不是我们通常在日常对话中所说的主题，而是更类似于 PCA 或 NMF（第 3 章\n",
    "讨论过这些内容）所提取的成分，它可能具有语义，也可能没有。即使 LDA“主题”具\n",
    "有语义，它可能也不是我们通常所说的主题。回到新闻文章的例子，我们可能有许多关\n",
    "于体育、政治和金融的文章，由两位作者所写。在一篇政治文章中，我们预计可能会看\n",
    "到“州长”“投票”“党派”等词语，而在一篇体育文章中，我们预计可能会看到类似“队\n",
    "伍”“得分”和“赛季”之类的词语。这两组词语可能会同时出现，而例如“队伍”和\n",
    "“州长”就不太可能同时出现。但是，这并不是我们预计可能同时出现的唯一的单词群组。\n",
    "这两位记者可能偏爱不同的短语或者选择不同的单词。可能其中一人喜欢使用“划界”\n",
    "（demarcate）这个词，而另一人喜欢使用“两极分化”（polarize）这个词。其他“主题”可\n",
    "能是“记者 A 常用的词语”和“记者 B 常用的词语”，虽然这并不是通常意义上的主题。\n",
    "我们将 LDA 应用于电影评论数据集，来看一下它在实践中的效果。对于无监督的文本文档\n",
    "模型，通常最好删除非常常见的单词，否则它们可能会支配分析过程。我们将删除至少在\n",
    "15% 的文档中出现过的单词，并在删除前 15% 之后，将词袋模型限定为最常见的 10 000 个\n",
    "单词：\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "reviews_train = load_files(\"train/\")\n",
    "# load_files返回一个Bunch对象，其中包含训练文本和训练标签\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "\n",
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "X = vect.fit_transform(text_train)\n",
    "'''\n",
    "将学习一个包含 10 个主题的主题模型，它包含的主题个数很少，我们可以查看所有\n",
    "主题。与 NMF 中的分量类似，主题没有内在的顺序，而改变主题数量将会改变所有主\n",
    "题。 15 我们将使用 \"batch\" 学习方法，它比默认方法（ \"online\" ）稍慢，但通常会给出更好\n",
    "的结果。我们还将增大 max_iter ，这样会得到更好的模型：\n",
    "'''\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_topics=10, learning_method=\"batch\",\n",
    "max_iter=25, random_state=0)\n",
    "# 我们在一个步骤中构建模型并变换数据\n",
    "# 计算变换需要花点时间，二者同时进行可以节省时间\n",
    "document_topics = lda.fit_transform(X)\n",
    "\n",
    "\n",
    "'''\n",
    "LatentDirichletAllocation 有一个 components_ 属性，\n",
    "其中保存了每个单词对每个主题的重要性。 components_ 的大小为 (n_topics, n_words) ：\n",
    "'''\n",
    "print(lda.components_.shape)\n",
    "\n",
    "import numpy as np\n",
    "# 对于每个主题（components_的一行），将特征排序（升序）\n",
    "# 用[:, ::-1]将行反转，使排序变为降序\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "# 从向量器中获取特征名称\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "\n",
    "import mglearn\n",
    "\n",
    "# 打印出前10个主题：\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names,\n",
    "sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}