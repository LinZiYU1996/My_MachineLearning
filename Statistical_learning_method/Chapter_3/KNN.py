# -*- coding: utf-8 -*-

# @Time  : 2019/12/2 13:34

# @Author : Mr.Lin


"""
K近邻

"""

import math
from itertools import combinations
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from collections import Counter

# p = 1 曼哈顿距离
# p = 2 欧氏距离
# p = inf 闵式距离minkowski_distance



# 根据欧式距离公式

def L(x,y,p=2):
    # x1 = [1, 1], x2 = [5,1]
    if len(x) == len(y) and len(x) > 1:
        sum = 0
        for i in range(len(x)):
            sum += math.pow(abs(x[i] - y[i]), p)
        return math.pow(sum, 1 / p)
    else:
        return 0

# 课本例3.1
x1 = [1, 1]
x2 = [5, 1]
x3 = [4, 4]


# x1, x2
# for i in range(1, 5):
#     r = { '1-{}'.format(c):L(x1, c, p=i) for c in [x2, x3]}
#     print(min(zip(r.values(), r.keys())))


# (4.0, '1-[5, 1]')
# (4.0, '1-[5, 1]')
# (3.7797631496846193, '1-[4, 4]')
# (3.5676213450081633, '1-[4, 4]')

# data
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['label'] = iris.target
df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
# data = np.array(df.iloc[:100, [0, 1, -1]])


plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')
plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')
plt.xlabel('sepal length')
plt.ylabel('sepal width')
plt.legend()



data = np.array(df.iloc[:100, [0, 1, -1]])
# print("data : \n",data)
print("")
print("")
X, y = data[:,:-1], data[:,-1]

# print("X : \n",X)
print("")
print("")

# print("y : \n",y)
print("")
print("")


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# print("X_train : \n",X_train)
print("")
print("")
print("")
print("")
# print("y_train : \n",y_train)

print("X_test :  \n",X_test)


class KNN:
    def __init__(self, X_train, y_train, n_neighbors=3, p=2):
        """
        parameter: n_neighbors 临近点个数
        parameter: p 距离度量
        """
        self.n = n_neighbors
        self.p = p
        self.X_train = X_train
        self.y_train = y_train

    def predict(self, X):
        # 取出n个点
        knn_list = []
        for i in range(self.n):
            print(" i ====",i)  #  0 1 2

            # np.linalg.norm(求范数)
            # 求得两个特征向量之间的距离

            dist = np.linalg.norm(X - self.X_train[i], ord=self.p)


            # print("dist : \n",dist)
            knn_list.append((dist, self.y_train[i]))


        print("")
        print("")
        print("")
        print("knn_list :  \n",knn_list)

        print("")
        print("")
        print("")



        for i in range(self.n, len(self.X_train)):
            print("max value : \n",max(knn_list, key=lambda x: x[0]))
            max_index = knn_list.index(max(knn_list, key=lambda x: x[0]))
            print("max index : \n",max_index)
            dist = np.linalg.norm(X - self.X_train[i], ord=self.p)
            if knn_list[max_index][0] > dist:
                knn_list[max_index] = (dist, self.y_train[i])


        # 数据从小到大 进行存放
        print("knn_list2 :  \n",knn_list)

        # 统计
        knn = [k[-1] for k in knn_list]
        print("knn : \n",knn)
        count_pairs = Counter(knn)
        print("count_pairs  : \n",count_pairs)


        # 最终的排序结果是从小到大


        max_count = sorted(count_pairs, key=lambda x: x)[-1]
        print("max_count : \n",max_count)
        return max_count

    def score(self, X_test, y_test):
        right_count = 0
        n = 10
        for X, y in zip(X_test, y_test):
            print("X , y in zip  : \n",X,y)
            print("**************************************'")
            print("")
        for X, y in zip(X_test, y_test):
            label = self.predict(X) # 调用预测模型
            if label == y:
                right_count += 1
        return right_count / len(X_test)





clf = KNN(X_train, y_train)

print(clf.score(X_test, y_test))



# 数据调试


# knn_list :
#  [(0.56568542494923812, 0.0), (1.8027756377319946, 1.0), (0.28284271247461895, 0.0)]
# knn_list :
#  [(1.0295630140987, 0.0), (0.98488578017960993, 1.0), (0.98994949366116647, 0.0)]
# knn_list :
#  [(0.64031242374328456, 0.0), (1.0, 1.0), (0.67082039324993659, 0.0)]
# knn_list :
#  [(0.79999999999999982, 0.0), (1.4317821063276348, 1.0), (0.63245553203367566, 0.0)]
# knn_list :
#  [(0.761577310586391, 0.0), (0.72801098892805116, 1.0), (0.90553851381374195, 0.0)]
# knn_list :
#  [(0.22360679774997916, 0.0), (1.708800749063506, 1.0), (0.30000000000000027, 0.0)]
# knn_list :
#  [(0.78102496759066553, 0.0), (0.90553851381374117, 1.0), (0.80622577482985502, 0.0)]
# knn_list :
#  [(0.7810249675906652, 0.0), (1.2806248474865696, 1.0), (1.0630145812734648, 0.0)]
# knn_list :
#  [(1.0295630140986995, 0.0), (0.5, 1.0), (1.1401754250991376, 0.0)]
# knn_list :
#  [(0.89442719099991552, 0.0), (1.0440306508910548, 1.0), (0.84852813742385658, 0.0)]
# knn_list :
#  [(0.58309518948452999, 0.0), (1.9104973174542794, 1.0), (0.31622776601683766, 0.0)]
# knn_list :
#  [(1.1401754250991381, 0.0), (1.2529964086141665, 1.0), (1.0295630140987, 0.0)]
# knn_list :
#  [(1.004987562112089, 0.0), (1.5811388300841898, 1.0), (0.80622577482985469, 0.0)]
# knn_list :
#  [(1.0816653826391964, 0.0), (0.50990195135927852, 1.0), (1.1704699910719623, 0.0)]
# knn_list :
#  [(1.0770329614269007, 0.0), (1.1180339887498949, 1.0), (0.99999999999999967, 0.0)]
# knn_list :
#  [(1.3892443989449808, 0.0), (2.2135943621178651, 1.0), (1.1180339887498949, 0.0)]
# knn_list :
#  [(0.31622776601683794, 0.0), (1.7, 1.0), (0.5099019513592784, 0.0)]
# knn_list :
#  [(1.0816653826391966, 0.0), (0.89442719099991563, 1.0), (1.0630145812734646, 0.0)]
# knn_list :
#  [(0.8062257748298548, 0.0), (0.72111025509279758, 1.0), (1.004987562112089, 0.0)]
# knn_list :
#  [(0.22360679774997916, 0.0), (1.2649110640673511, 1.0), (0.4123105625617664, 0.0)]




# data :
#  [[ 5.1  3.5  0. ]
#  [ 4.9  3.   0. ]
#  [ 4.7  3.2  0. ]
#  [ 4.6  3.1  0. ]
#  [ 5.   3.6  0. ]
#  [ 5.4  3.9  0. ]
#  [ 4.6  3.4  0. ]
#  [ 5.   3.4  0. ]
#  [ 4.4  2.9  0. ]
#  [ 4.9  3.1  0. ]
#  [ 5.4  3.7  0. ]
#  [ 4.8  3.4  0. ]
#  [ 4.8  3.   0. ]
#  [ 4.3  3.   0. ]
#  [ 5.8  4.   0. ]
#  [ 5.7  4.4  0. ]
#  [ 5.4  3.9  0. ]
#  [ 5.1  3.5  0. ]
#  [ 5.7  3.8  0. ]
#  [ 5.1  3.8  0. ]
#  [ 5.4  3.4  0. ]
#  [ 5.1  3.7  0. ]
#  [ 4.6  3.6  0. ]
#  [ 5.1  3.3  0. ]
#  [ 4.8  3.4  0. ]
#  [ 5.   3.   0. ]
#  [ 5.   3.4  0. ]
#  [ 5.2  3.5  0. ]
#  [ 5.2  3.4  0. ]
#  [ 4.7  3.2  0. ]
#  [ 4.8  3.1  0. ]
#  [ 5.4  3.4  0. ]
#  [ 5.2  4.1  0. ]
#  [ 5.5  4.2  0. ]
#  [ 4.9  3.1  0. ]
#  [ 5.   3.2  0. ]
#  [ 5.5  3.5  0. ]
#  [ 4.9  3.1  0. ]
#  [ 4.4  3.   0. ]
#  [ 5.1  3.4  0. ]
#  [ 5.   3.5  0. ]
#  [ 4.5  2.3  0. ]
#  [ 4.4  3.2  0. ]
#  [ 5.   3.5  0. ]
#  [ 5.1  3.8  0. ]
#  [ 4.8  3.   0. ]
#  [ 5.1  3.8  0. ]
#  [ 4.6  3.2  0. ]
#  [ 5.3  3.7  0. ]
#  [ 5.   3.3  0. ]
#  [ 7.   3.2  1. ]
#  [ 6.4  3.2  1. ]
#  [ 6.9  3.1  1. ]
#  [ 5.5  2.3  1. ]
#  [ 6.5  2.8  1. ]
#  [ 5.7  2.8  1. ]
#  [ 6.3  3.3  1. ]
#  [ 4.9  2.4  1. ]
#  [ 6.6  2.9  1. ]
#  [ 5.2  2.7  1. ]
#  [ 5.   2.   1. ]
#  [ 5.9  3.   1. ]
#  [ 6.   2.2  1. ]
#  [ 6.1  2.9  1. ]
#  [ 5.6  2.9  1. ]
#  [ 6.7  3.1  1. ]
#  [ 5.6  3.   1. ]
#  [ 5.8  2.7  1. ]
#  [ 6.2  2.2  1. ]
#  [ 5.6  2.5  1. ]
#  [ 5.9  3.2  1. ]
#  [ 6.1  2.8  1. ]
#  [ 6.3  2.5  1. ]
#  [ 6.1  2.8  1. ]
#  [ 6.4  2.9  1. ]
#  [ 6.6  3.   1. ]
#  [ 6.8  2.8  1. ]
#  [ 6.7  3.   1. ]
#  [ 6.   2.9  1. ]
#  [ 5.7  2.6  1. ]
#  [ 5.5  2.4  1. ]
#  [ 5.5  2.4  1. ]
#  [ 5.8  2.7  1. ]
#  [ 6.   2.7  1. ]
#  [ 5.4  3.   1. ]
#  [ 6.   3.4  1. ]
#  [ 6.7  3.1  1. ]
#  [ 6.3  2.3  1. ]
#  [ 5.6  3.   1. ]
#  [ 5.5  2.5  1. ]
#  [ 5.5  2.6  1. ]
#  [ 6.1  3.   1. ]
#  [ 5.8  2.6  1. ]
#  [ 5.   2.3  1. ]
#  [ 5.6  2.7  1. ]
#  [ 5.7  3.   1. ]
#  [ 5.7  2.9  1. ]
#  [ 6.2  2.9  1. ]
#  [ 5.1  2.5  1. ]
#  [ 5.7  2.8  1. ]]
#
#
# X :
#  [[ 5.1  3.5]
#  [ 4.9  3. ]
#  [ 4.7  3.2]
#  [ 4.6  3.1]
#  [ 5.   3.6]
#  [ 5.4  3.9]
#  [ 4.6  3.4]
#  [ 5.   3.4]
#  [ 4.4  2.9]
#  [ 4.9  3.1]
#  [ 5.4  3.7]
#  [ 4.8  3.4]
#  [ 4.8  3. ]
#  [ 4.3  3. ]
#  [ 5.8  4. ]
#  [ 5.7  4.4]
#  [ 5.4  3.9]
#  [ 5.1  3.5]
#  [ 5.7  3.8]
#  [ 5.1  3.8]
#  [ 5.4  3.4]
#  [ 5.1  3.7]
#  [ 4.6  3.6]
#  [ 5.1  3.3]
#  [ 4.8  3.4]
#  [ 5.   3. ]
#  [ 5.   3.4]
#  [ 5.2  3.5]
#  [ 5.2  3.4]
#  [ 4.7  3.2]
#  [ 4.8  3.1]
#  [ 5.4  3.4]
#  [ 5.2  4.1]
#  [ 5.5  4.2]
#  [ 4.9  3.1]
#  [ 5.   3.2]
#  [ 5.5  3.5]
#  [ 4.9  3.1]
#  [ 4.4  3. ]
#  [ 5.1  3.4]
#  [ 5.   3.5]
#  [ 4.5  2.3]
#  [ 4.4  3.2]
#  [ 5.   3.5]
#  [ 5.1  3.8]
#  [ 4.8  3. ]
#  [ 5.1  3.8]
#  [ 4.6  3.2]
#  [ 5.3  3.7]
#  [ 5.   3.3]
#  [ 7.   3.2]
#  [ 6.4  3.2]
#  [ 6.9  3.1]
#  [ 5.5  2.3]
#  [ 6.5  2.8]
#  [ 5.7  2.8]
#  [ 6.3  3.3]
#  [ 4.9  2.4]
#  [ 6.6  2.9]
#  [ 5.2  2.7]
#  [ 5.   2. ]
#  [ 5.9  3. ]
#  [ 6.   2.2]
#  [ 6.1  2.9]
#  [ 5.6  2.9]
#  [ 6.7  3.1]
#  [ 5.6  3. ]
#  [ 5.8  2.7]
#  [ 6.2  2.2]
#  [ 5.6  2.5]
#  [ 5.9  3.2]
#  [ 6.1  2.8]
#  [ 6.3  2.5]
#  [ 6.1  2.8]
#  [ 6.4  2.9]
#  [ 6.6  3. ]
#  [ 6.8  2.8]
#  [ 6.7  3. ]
#  [ 6.   2.9]
#  [ 5.7  2.6]
#  [ 5.5  2.4]
#  [ 5.5  2.4]
#  [ 5.8  2.7]
#  [ 6.   2.7]
#  [ 5.4  3. ]
#  [ 6.   3.4]
#  [ 6.7  3.1]
#  [ 6.3  2.3]
#  [ 5.6  3. ]
#  [ 5.5  2.5]
#  [ 5.5  2.6]
#  [ 6.1  3. ]
#  [ 5.8  2.6]
#  [ 5.   2.3]
#  [ 5.6  2.7]
#  [ 5.7  3. ]
#  [ 5.7  2.9]
#  [ 6.2  2.9]
#  [ 5.1  2.5]
#  [ 5.7  2.8]]
#
#
# y :
#  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
#   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
#   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.
#   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
#   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
#   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
#
#
# X_train :
#  [[ 6.   3.4]
#  [ 4.7  3.2]
#  [ 4.7  3.2]
#  [ 5.   3.4]
#  [ 6.2  2.9]
#  [ 5.   3. ]
#  [ 4.8  3.1]
#  [ 5.4  3.4]
#  [ 5.2  4.1]
#  [ 5.7  2.6]
#  [ 6.3  2.3]
#  [ 5.7  3. ]
#  [ 4.8  3.4]
#  [ 5.5  3.5]
#  [ 5.8  4. ]
#  [ 5.8  2.7]
#  [ 6.8  2.8]
#  [ 4.8  3. ]
#  [ 5.1  3.8]
#  [ 6.   2.9]
#  [ 5.   3.6]
#  [ 6.7  3. ]
#  [ 5.4  3.4]
#  [ 5.2  3.5]
#  [ 6.3  3.3]
#  [ 5.7  4.4]
#  [ 4.5  2.3]
#  [ 5.3  3.7]
#  [ 5.7  2.8]
#  [ 6.1  2.8]
#  [ 5.6  2.7]
#  [ 5.1  3.8]
#  [ 5.5  2.3]
#  [ 4.6  3.4]
#  [ 5.8  2.6]
#  [ 5.5  2.4]
#  [ 5.1  3.4]
#  [ 6.9  3.1]
#  [ 4.9  3.1]
#  [ 5.7  2.8]
#  [ 5.1  3.3]
#  [ 5.6  3. ]
#  [ 5.1  3.8]
#  [ 5.1  3.7]
#  [ 5.   3.5]
#  [ 4.4  2.9]
#  [ 6.7  3.1]
#  [ 5.4  3.9]
#  [ 5.   3.2]
#  [ 4.8  3. ]
#  [ 4.6  3.6]
#  [ 5.1  3.5]
#  [ 5.   3.3]
#  [ 5.   2.3]
#  [ 6.2  2.2]
#  [ 4.4  3. ]
#  [ 5.4  3.7]
#  [ 5.7  2.9]
#  [ 5.8  2.7]
#  [ 5.6  3. ]
#  [ 5.1  2.5]
#  [ 6.   2.2]
#  [ 5.4  3. ]
#  [ 6.6  3. ]
#  [ 5.   3.4]
#  [ 5.5  4.2]
#  [ 4.9  3.1]
#  [ 5.5  2.5]
#  [ 6.1  2.8]
#  [ 5.1  3.5]
#  [ 4.9  3. ]
#  [ 6.5  2.8]
#  [ 6.3  2.5]
#  [ 5.9  3.2]
#  [ 4.8  3.4]
#  [ 7.   3.2]
#  [ 5.2  2.7]
#  [ 4.9  2.4]
#  [ 6.1  2.9]
#  [ 5.   3.5]]
#
#
#
#
# y_train :
#  [ 1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.
#   0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
#   0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
#   1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.
#   1.  1.  0.  1.  1.  1.  1.  0.]




# X_test :
#  [[ 6.1  2.8]
#  [ 6.1  3. ]
#  [ 5.1  3.7]
#  [ 5.1  3.5]
#  [ 5.   3.5]
#  [ 5.3  3.7]
#  [ 4.4  3. ]
#  [ 5.1  3.5]
#  [ 4.9  3.1]
#  [ 5.   3.4]
#  [ 5.4  3.4]
#  [ 5.8  2.7]
#  [ 5.4  3. ]
#  [ 5.8  2.6]
#  [ 4.8  3.1]
#  [ 6.9  3.1]
#  [ 5.   3.4]
#  [ 5.5  2.4]
#  [ 5.   2.3]
#  [ 5.5  2.6]]














































































